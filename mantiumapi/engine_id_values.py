default_ai_engines = [
    {
        'ai_engine_id': 'b2ffecf7-4fee-42e7-b85d-a5e28d939396',
        'name': 'davinci',
        'description': """Davinci is the most capable engine and can perform any task the other models can perform and often with less instruction. For applications requiring a lot of understanding of the content, like summarization for a specific audience and content creative generation, Davinci is going to produce the best results. The trade-off with Davinci is that it costs more to use per API call and other engines are faster.
Another area where Davinci shines is in understanding the intent of text. Davinci is quite good at solving many kinds of logic problems and explaining the motives of characters. Davinci has been able to solve some of the most challenging AI problems involving cause and effect.""",
        'use_cases': 'Complex intent, cause and effect, summarization for audience',
        'ai_provider': 'OpenAI',
        'cost_ranking': 100,
        'status': 'READY',
    },
    {
        'ai_engine_id': 'b26dd8d0-efc4-45ef-899a-fad0ff93e258',
        'name': 'curie',
        'description': 'Curie is extremely powerful, yet very fast. While Davinci is stronger when it comes to analyzing complicated text, Curie is quite capable for many nuanced tasks like sentiment classification and summarization. Curie is also quite good at answering questions and performing Q&A and as a general service chatbot.',
        'use_cases': 'Language translation, complex classification, text sentiment, summarization',
        'ai_provider': 'OpenAI',
        'cost_ranking': 90,
        'status': 'READY',
    },
    {
        'ai_engine_id': 'aa88258f-adbe-4259-9992-232bb5ff75b4',
        'name': 'babbage',
        'description': 'Babbage can perform straightforward tasks like simple classification. It’s also quite capable when it comes to Semantic Search ranking how well documents match up with search queries.',
        'use_cases': 'Moderate classification, semantic search classification',
        'ai_provider': 'OpenAI',
        'cost_ranking': 80,
        'status': 'READY',
    },
    {
        'ai_engine_id': 'ce6850ef-bc78-4f7a-af5f-81fb9d9fb872',
        'name': 'ada',
        'description': 'Ada is usually the fastest model and can perform tasks like parsing text, address correction and certain kinds of classification tasks that don’t require too much nuance. Ada’s performance can often be improved by providing more context.',
        'use_cases': 'Parsing text, simple classification, address correction, keywords',
        'ai_provider': 'OpenAI',
        'cost_ranking': 70,
        'status': 'READY',
    },
    {
        'ai_engine_id': 'a5b48665-a180-4c3c-9e02-a5506317c13a',
        'name': 'davinci-codex',
        'description': 'The Codex models are descendants of base GPT-3 models that can understand and generate code. ',
        'use_cases': 'translates natural language to code',
        'ai_provider': 'OpenAI',
        'cost_ranking': 60,
        'status': 'READY',
    },
    {
        'ai_engine_id': 'b18395a0-191c-4b85-a9a3-159facd83c28',
        'name': 'cushman-codex',
        'description': 'The Codex models are descendants of base GPT-3 models that can understand and generate code. ',
        'use_cases': 'translates natural language to code',
        'ai_provider': 'OpenAI',
        'cost_ranking': 60,
        'status': 'READY',
    },
    {
        'ai_engine_id': '34dd5e1f-2557-4f7f-b5b2-d3eccfb00ad7',
        'name': 'content-filter-alpha-c4',
        'description': '',
        'use_cases': '',
        'ai_provider': 'OpenAI',
        'cost_ranking': 0,
        'status': 'READY',
    },
    {
        'ai_engine_id': '2d061d32-ac88-4934-8e30-88f7c1710bbb',
        'name': 'content-filter-dev',
        'description': '',
        'use_cases': '',
        'ai_provider': 'OpenAI',
        'cost_ranking': 0,
        'status': 'READY',
    },
    {
        'ai_engine_id': '30cc43da-1724-4988-b6dd-72a29328a578',
        'name': 'curie-instruct-beta',
        'description': '',
        'use_cases': '',
        'ai_provider': 'OpenAI',
        'cost_ranking': 0,
        'status': 'READY',
    },
    {
        'ai_engine_id': '78399e12-fa98-4dd5-8800-2fc41b28033f',
        'name': 'cursing-filter-v6',
        'description': '',
        'use_cases': '',
        'ai_provider': 'OpenAI',
        'cost_ranking': 0,
        'status': 'READY',
    },
    {
        'ai_engine_id': '3f7e30f4-46b6-4338-b825-ffb4e87f69c8',
        'name': 'davinci-instruct-beta',
        'description': '',
        'use_cases': '',
        'ai_provider': 'OpenAI',
        'cost_ranking': 0,
        'status': 'READY',
    },
    {
        'ai_engine_id': 'a7beb6e1-a107-41ad-b7a1-f1ba97d064a3',
        'name': 'baseline-shrimp',
        'description': 'Smallest Universal Model.  SentEval Benchmarks:  Similarity Tasks 0.82, Downstream Tasks: 0.81, Probing Tasks: 0.71',
        'use_cases': 'generate, likelihood, choose-best, embed, similarity',
        'ai_provider': 'Cohere',
        'cost_ranking': 24,
        'status': 'READY',
    },
    {
        'ai_engine_id': 'd211007a-ba0f-4f08-a528-11ec74cd2d71',
        'name': 'baseline-otter',
        'description': 'Representation Model.  SentEval Benchmarks:  Similarity Tasks 0.82, Downstream Tasks: 0.82, Probing Tasks: 0.67',
        'use_cases': 'generate, likelihood, choose-best',
        'ai_provider': 'Cohere',
        'cost_ranking': 192,
        'status': 'READY',
    },
    {
        'ai_engine_id': '4718cd5f-8c41-489a-8939-7a3e86a15036',
        'name': 'baseline-seal',
        'description': 'Representation Model.  SentEval Benchmarks:  Similarity Tasks 0.82, Downstream Tasks: 0.82, Probing Tasks: 0.67',
        'use_cases': 'generate, likelihood, choose-best',
        'ai_provider': 'Cohere',
        'cost_ranking': 699,
        'status': 'READY',
    },
    {
        'ai_engine_id': 'aeb0aa7b-8ed3-451a-9b47-0914cae72929',
        'name': 'baseline-shark',
        'description': '2nd Largest Generation Model',
        'use_cases': 'generate, likelihood, choose-best',
        'ai_provider': 'Cohere',
        'cost_ranking': 2796,
        'status': 'READY',
    },
    {
        'ai_engine_id': '34c97424-df6a-4e9d-adbe-97f7d4acc4b8',
        'name': 'baseline-orca',
        'description': 'Largest Generation Model',
        'use_cases': 'generate, likelihood, choose-best',
        'ai_provider': 'Cohere',
        'cost_ranking': 5000,
        'status': 'READY',
    },
    {
        'ai_engine_id': '8745e877-aa89-499a-a364-072473b9cf07',
        'name': 'iron',
        'description': ' Mantium Generation Model',
        'use_cases': 'generate',
        'ai_provider': 'Mantium',
        'cost_ranking': 5200,
        'status': 'READY',
    },
    {
        'ai_engine_id': '2d11947c-8407-4438-ae2b-63021a726bb9',
        'name': 'j1-large',
        'description': ' Ai21 Generation Model',
        'use_cases': 'generate',
        'ai_provider': 'Ai21',
        'cost_ranking': 5200,
        'status': 'READY',
    },
    {
        'ai_engine_id': '5dbbc52a-147f-4920-b8b0-ef198c9888a3',
        'name': 'j1-jumbo',
        'description': ' Ai21 Generation Model',
        'use_cases': 'generate',
        'ai_provider': 'Ai21',
        'cost_ranking': 5200,
        'status': 'READY',
    },
]
